{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e78aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -U -q streamlit pyngrok datasets huggingface_hub fsspec gdown transformers nltk sentence_transformers faiss-cpu\n",
    "!pip install -q streamlit-chat\n",
    "\n",
    "# Clone the Spider dataset repository\n",
    "!git clone https://github.com/shu4dev/Spider_RAG.git\n",
    "%cd Spider_RAG\n",
    "!gdown 1403EGqzIDoHMdQF4c9Bkyl7dZLZ5Wt6J\n",
    "!unzip -o spider_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774da637",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import gc\n",
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import faiss\n",
    "import spacy\n",
    "import random\n",
    "import pickle\n",
    "import hashlib\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "from process_sql import Schema, get_schema, get_sql\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b73293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "@st.cache_resource\n",
    "def setup_nltk():\n",
    "    nltk.download('punkt_tab')\n",
    "    return True\n",
    "\n",
    "# Load spacy model\n",
    "@st.cache_resource\n",
    "def load_spacy():\n",
    "    return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Set page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Spider RAG SQL Generator\",\n",
    "    page_icon=\"🕷️\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Initialize session state\n",
    "if 'initialized' not in st.session_state:\n",
    "    st.session_state.initialized = False\n",
    "    st.session_state.query_history = []\n",
    "    st.session_state.current_result = None\n",
    "\n",
    "# Global variables\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "LLM_MODEL_NAME = \"Qwen/Qwen2.5-Coder-14B-Instruct\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TOP_K_COLUMNS = 10\n",
    "\n",
    "# Initialize globals\n",
    "if not st.session_state.initialized:\n",
    "    setup_nltk()\n",
    "    nlp = load_spacy()\n",
    "    \n",
    "    # Load schema\n",
    "    schema_file = Path(\"spider_data/tables.json\")\n",
    "    schema_all = json.loads(schema_file.read_text())\n",
    "    schema = next(d for d in schema_all if d[\"db_id\"] == \"department_store\")\n",
    "    tables = schema[\"table_names_original\"]\n",
    "    columns_orig = schema[\"column_names_original\"]\n",
    "    foreign_pairs = schema[\"foreign_keys\"]\n",
    "    pk_set = set(schema[\"primary_keys\"])\n",
    "    \n",
    "    # Store in session state\n",
    "    st.session_state.nlp = nlp\n",
    "    st.session_state.schema = schema\n",
    "    st.session_state.tables = tables\n",
    "    st.session_state.columns_orig = columns_orig\n",
    "    st.session_state.foreign_pairs = foreign_pairs\n",
    "    st.session_state.pk_set = pk_set\n",
    "    st.session_state.G = nx.MultiDiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions (simplified versions from the original script)\n",
    "def get_random_row_with_all_strings(cursor, table_name):\n",
    "    \"\"\"Get a random row and all possible values from VARCHAR columns.\"\"\"\n",
    "    try:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        if row_count == 0:\n",
    "            return None\n",
    "            \n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns_info = cursor.fetchall()\n",
    "        columns = [column[1] for column in columns_info]\n",
    "        \n",
    "        cursor.execute(f\"SELECT * FROM {table_name} ORDER BY RANDOM() LIMIT 1\")\n",
    "        random_row = cursor.fetchone()\n",
    "        \n",
    "        # Get VARCHAR columns\n",
    "        varchar_columns = []\n",
    "        for column in columns_info:\n",
    "            column_name = column[1]\n",
    "            column_type = column[2].strip().upper() if column[2] else ''\n",
    "            if column_type.startswith('VARCHAR') and column_type != 'VARCHAR(255)':\n",
    "                varchar_columns.append(column_name)\n",
    "        \n",
    "        # Get all unique values\n",
    "        all_values = {}\n",
    "        for col in varchar_columns:\n",
    "            cursor.execute(f'SELECT DISTINCT \"{col}\" FROM {table_name} WHERE \"{col}\" IS NOT NULL')\n",
    "            values = [row[0] for row in cursor.fetchall() if isinstance(row[0], str)]\n",
    "            all_values[col] = values\n",
    "            \n",
    "        return {\n",
    "            'random_row': random_row,\n",
    "            'columns': columns,\n",
    "            'row_dict': dict(zip(columns, random_row)) if random_row else None,\n",
    "            'all_string_values': all_values,\n",
    "            'varchar_columns': varchar_columns\n",
    "        }\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def database_value(table_name):\n",
    "    \"\"\"Access database and get random row data.\"\"\"\n",
    "    db_path = \"spider_data/database/department_store/department_store.sqlite\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        result = get_random_row_with_all_strings(cursor, table_name)\n",
    "        conn.close()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        st.error(f\"Database error: {e}\")\n",
    "        return None\n",
    "\n",
    "@st.cache_resource\n",
    "def initialize_graph():\n",
    "    \"\"\"Initialize the knowledge graph.\"\"\"\n",
    "    G = nx.MultiDiGraph()\n",
    "    tables = st.session_state.tables\n",
    "    columns_orig = st.session_state.columns_orig\n",
    "    foreign_pairs = st.session_state.foreign_pairs\n",
    "    pk_set = st.session_state.pk_set\n",
    "    \n",
    "    G.add_nodes_from(tables)\n",
    "    colidx_to_tbl = {i: tables[tbl_id] for i, (tbl_id, _) in enumerate(columns_orig) if tbl_id != -1}\n",
    "    \n",
    "    # Add foreign key edges\n",
    "    for child_idx, parent_idx in foreign_pairs:\n",
    "        child_tbl = colidx_to_tbl[child_idx]\n",
    "        parent_tbl = colidx_to_tbl[parent_idx]\n",
    "        child_col = columns_orig[child_idx][1]\n",
    "        parent_col = columns_orig[parent_idx][1]\n",
    "        G.add_edge(child_tbl, parent_tbl,\n",
    "                  relation=\"foreign_key\",\n",
    "                  fk=f\"{parent_col} -> {child_col}\")\n",
    "    \n",
    "    # Add column nodes\n",
    "    table_data_cache = {}\n",
    "    fk_child_set = {c for c, _ in foreign_pairs}\n",
    "    \n",
    "    for idx, (tbl_id, col_nm) in enumerate(columns_orig):\n",
    "        if tbl_id == -1:\n",
    "            continue\n",
    "            \n",
    "        tbl = tables[tbl_id]\n",
    "        \n",
    "        if tbl not in table_data_cache:\n",
    "            table_data_cache[tbl] = database_value(tbl)\n",
    "            \n",
    "        table_data = table_data_cache[tbl]\n",
    "        col_node = f\"{tbl}.{col_nm}\"\n",
    "        \n",
    "        node_attrs = {\n",
    "            \"type\": \"column\",\n",
    "            \"label\": col_nm,\n",
    "            \"pk\": idx in pk_set,\n",
    "            \"fk\": idx in fk_child_set\n",
    "        }\n",
    "        \n",
    "        if table_data and 'row_dict' in table_data and col_nm in table_data['row_dict']:\n",
    "            node_attrs[\"value\"] = table_data['row_dict'][col_nm]\n",
    "        else:\n",
    "            node_attrs[\"value\"] = None\n",
    "            \n",
    "        if (table_data and 'varchar_columns' in table_data and \n",
    "            col_nm in table_data['varchar_columns'] and\n",
    "            'all_string_values' in table_data and\n",
    "            col_nm in table_data['all_string_values']):\n",
    "            node_attrs[\"all_values\"] = table_data['all_string_values'][col_nm]\n",
    "            node_attrs[\"has_all_values\"] = True\n",
    "            \n",
    "        G.add_node(col_node, **node_attrs)\n",
    "        G.add_edge(tbl, col_node, relation=\"has_column\")\n",
    "    \n",
    "    ROOT_TABLES = [t for t in tables if G.in_degree(t) == 0]\n",
    "    return G, ROOT_TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def load_embeddings(folder_name=\"BAAI-bge-m3\"):\n",
    "    \"\"\"Load pre-computed embeddings.\"\"\"\n",
    "    try:\n",
    "        with open(f\"{folder_name}/query_embeds.pkl\", \"rb\") as f:\n",
    "            query_embeds = pickle.load(f)\n",
    "        with open(f\"{folder_name}/table_embeds.pkl\", \"rb\") as f:\n",
    "            table_embeds = pickle.load(f)\n",
    "        with open(f\"{folder_name}/documents.pkl\", \"rb\") as f:\n",
    "            documents = pickle.load(f)\n",
    "        with open(f\"{folder_name}/column_embeds.pkl\", \"rb\") as f:\n",
    "            column_embeds = pickle.load(f)\n",
    "        return query_embeds, table_embeds, documents, column_embeds\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading embeddings: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    \"\"\"Load the embedding model and LLM.\"\"\"\n",
    "    with st.spinner(\"Loading models... This may take a few minutes.\"):\n",
    "        # Load embedding model\n",
    "        embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=DEVICE)\n",
    "        \n",
    "        # Load LLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            LLM_MODEL_NAME, \n",
    "        )\n",
    "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "            LLM_MODEL_NAME,\n",
    "            torch_dtype=torch.bfloat16 if DEVICE == \"cuda\" else torch.float32\n",
    "        )\n",
    "        llm_model.to(DEVICE)\n",
    "        llm_model.eval()\n",
    "        \n",
    "    return embed_model, tokenizer, llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main UI\n",
    "st.title(\"🕷️ Spider RAG SQL Generator\")\n",
    "st.markdown(\"\"\"\n",
    "This interface generates SQL queries for the department store database using RAG (Retrieval-Augmented Generation).\n",
    "Ask natural language questions and get SQL queries!\n",
    "\"\"\")\n",
    "\n",
    "# Sidebar\n",
    "with st.sidebar:\n",
    "    st.header(\"⚙️ Settings\")\n",
    "    \n",
    "    # Model selection\n",
    "    embedding_choice = st.selectbox(\n",
    "        \"Embedding Model\",\n",
    "        [\"BAAI-bge-m3\", \"BAAI-bge-large-en-v1.5\", \"Qwen3-Embedding-8B\"],\n",
    "        index=0\n",
    "    )\n",
    "    \n",
    "    # Retrieval settings\n",
    "    k_examples = st.slider(\"Number of examples to retrieve\", 1, 10, 3)\n",
    "    num_samples = st.slider(\"Number of SQL candidates to generate\", 1, 10, 6)\n",
    "    \n",
    "    # Generation settings\n",
    "    with st.expander(\"Generation Parameters\"):\n",
    "        temperature = st.slider(\"Temperature\", 0.1, 1.0, 0.7)\n",
    "        top_p = st.slider(\"Top-p\", 0.1, 1.0, 0.8)\n",
    "        top_k = st.slider(\"Top-k\", 1, 50, 20)\n",
    "        max_length = st.slider(\"Max generation length\", 64, 512, 256)\n",
    "    \n",
    "    # Database schema viewer\n",
    "    with st.expander(\"📊 Database Schema\"):\n",
    "        if st.session_state.initialized:\n",
    "            for table in st.session_state.tables:\n",
    "                st.write(f\"**{table}**\")\n",
    "                # Show columns for this table\n",
    "                cols = [col for tid, col in st.session_state.columns_orig \n",
    "                       if tid != -1 and st.session_state.tables[tid] == table]\n",
    "                for col in cols:\n",
    "                    st.write(f\"  - {col}\")\n",
    "\n",
    "# Initialize system\n",
    "if st.button(\"🚀 Initialize System\", disabled=st.session_state.initialized):\n",
    "    with st.spinner(\"Initializing system...\"):\n",
    "        # Initialize graph\n",
    "        G, ROOT_TABLES = initialize_graph()\n",
    "        st.session_state.G = G\n",
    "        st.session_state.ROOT_TABLES = ROOT_TABLES\n",
    "        \n",
    "        # Load embeddings\n",
    "        folder_map = {\n",
    "            \"BAAI-bge-m3\": \"BAAI-bge-m3\",\n",
    "            \"BAAI-bge-large-en-v1.5\": \"BAAI-bge-large-en-v1.5\",\n",
    "            \"Qwen3-Embedding-8B\": \"Qwen3-Embedding-8B\"\n",
    "        }\n",
    "        \n",
    "        query_embeds, table_embeds, documents, column_embeds = load_embeddings(folder_map[embedding_choice])\n",
    "        \n",
    "        if all(x is not None for x in [query_embeds, table_embeds, documents, column_embeds]):\n",
    "            st.session_state.QUERY_EMBEDS = query_embeds\n",
    "            st.session_state.TABLE_EMBEDS = table_embeds\n",
    "            st.session_state.DOCUMENTS = documents\n",
    "            st.session_state.COLUMN_EMBEDS = column_embeds\n",
    "            \n",
    "            # Load models\n",
    "            embed_model, tokenizer, llm_model = load_models()\n",
    "            st.session_state.embed_model = embed_model\n",
    "            st.session_state.tokenizer = tokenizer\n",
    "            st.session_state.llm_model = llm_model\n",
    "            \n",
    "            st.session_state.initialized = True\n",
    "            st.success(\"System initialized successfully!\")\n",
    "        else:\n",
    "            st.error(\"Failed to load embeddings. Please check the files.\")\n",
    "\n",
    "# Main interface\n",
    "if st.session_state.initialized:\n",
    "    # Query input\n",
    "    st.header(\"💬 Ask a Question\")\n",
    "    \n",
    "    col1, col2 = st.columns([3, 1])\n",
    "    with col1:\n",
    "        user_question = st.text_input(\n",
    "            \"Enter your question about the department store database:\",\n",
    "            placeholder=\"e.g., What is the total sales amount for each department?\"\n",
    "        )\n",
    "    with col2:\n",
    "        generate_btn = st.button(\"Generate SQL\", type=\"primary\", disabled=not user_question)\n",
    "    \n",
    "    # Example questions\n",
    "    with st.expander(\"📝 Example Questions\"):\n",
    "        example_questions = [\n",
    "            \"What is the total sales amount for each department?\",\n",
    "            \"Which customers have made purchases over $100?\",\n",
    "            \"List all products with their current stock levels\",\n",
    "            \"Show the top 5 best-selling products\",\n",
    "            \"Find all orders placed in the last month\"\n",
    "        ]\n",
    "        for q in example_questions:\n",
    "            if st.button(q, key=f\"ex_{q[:20]}\"):\n",
    "                user_question = q\n",
    "                generate_btn = True\n",
    "    \n",
    "    # Generate SQL\n",
    "    if generate_btn and user_question:\n",
    "        with st.spinner(\"Generating SQL query...\"):\n",
    "            try:\n",
    "                # Embed the question\n",
    "                q_vec = st.session_state.embed_model.encode(\n",
    "                    [user_question],\n",
    "                    convert_to_numpy=True,\n",
    "                    normalize_embeddings=True\n",
    "                )[0]\n",
    "                \n",
    "                # Create query dict\n",
    "                query = {\n",
    "                    \"question\": user_question,\n",
    "                    \"embedding\": q_vec,\n",
    "                    \"db_id\": \"department_store\"\n",
    "                }\n",
    "                \n",
    "                # Retrieve similar examples\n",
    "                similarities = [q_vec @ doc[\"embedding\"].T for doc in st.session_state.DOCUMENTS]\n",
    "                idxs = np.argsort(similarities)[-k_examples:][::-1]\n",
    "                retrieved_docs = [st.session_state.DOCUMENTS[i] for i in idxs]\n",
    "                \n",
    "                # Show retrieved examples\n",
    "                with st.expander(\"🔍 Retrieved Examples\"):\n",
    "                    for i, doc in enumerate(retrieved_docs):\n",
    "                        st.write(f\"**Example {i+1}:**\")\n",
    "                        st.write(f\"Question: {doc['question']}\")\n",
    "                        st.code(doc['query'], language='sql')\n",
    "                        st.write(\"---\")\n",
    "                \n",
    "                # Generate SQL (simplified version)\n",
    "                st.info(\"Generating SQL query...\")\n",
    "                \n",
    "                # Create a simple prompt\n",
    "                prompt = f\"\"\"You are an SQL expert. Based on the department store database schema,\n",
    "                generate an SQL query for this question: {user_question}\n",
    "                \n",
    "                Return only the SQL query, no explanations.\"\"\"\n",
    "                \n",
    "                # Show the generated SQL\n",
    "                generated_sql = \"SELECT * FROM departments;\"  # Placeholder\n",
    "                \n",
    "                st.success(\"SQL query generated!\")\n",
    "                st.code(generated_sql, language='sql')\n",
    "                \n",
    "                # Save to history\n",
    "                st.session_state.query_history.append({\n",
    "                    \"question\": user_question,\n",
    "                    \"sql\": generated_sql,\n",
    "                    \"timestamp\": \"2025-01-07\"\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"Error generating SQL: {str(e)}\")\n",
    "    \n",
    "    # Query history\n",
    "    if st.session_state.query_history:\n",
    "        st.header(\"📜 Query History\")\n",
    "        for i, item in enumerate(reversed(st.session_state.query_history)):\n",
    "            with st.expander(f\"Query {len(st.session_state.query_history) - i}: {item['question'][:50]}...\"):\n",
    "                st.write(f\"**Question:** {item['question']}\")\n",
    "                st.code(item['sql'], language='sql')\n",
    "                st.write(f\"*Generated at: {item['timestamp']}*\")\n",
    "\n",
    "else:\n",
    "    st.info(\"👆 Click 'Initialize System' to start using the SQL generator.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"Built with Streamlit and Spider RAG System\")\n",
    "\n",
    "# Run the Streamlit app with ngrok\n",
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Set up ngrok\n",
    "ngrok_token = \"YOUR_NGROK_TOKEN\"  # Replace with your ngrok token\n",
    "ngrok.set_auth_token(ngrok_token)\n",
    "\n",
    "# Run Streamlit in background\n",
    "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
    "time.sleep(5)  # Wait for Streamlit to start\n",
    "\n",
    "# Create ngrok tunnel\n",
    "public_url = ngrok.connect(8501)\n",
    "print(f\"\\n🌐 Your Streamlit app is live at: {public_url}\")\n",
    "print(\"Click the link above to access your Spider RAG interface!\")\n",
    "\n",
    "# Keep the process running\n",
    "try:\n",
    "    process.wait()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nShutting down...\")\n",
    "    ngrok.disconnect(public_url)\n",
    "    process.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
